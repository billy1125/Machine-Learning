{"cells":[{"cell_type":"markdown","id":"01fb7819","metadata":{"id":"01fb7819"},"source":["# MNIST 手寫辨識：從零實作 CNN（NumPy）與 Keras CNN 版本\n","\n","這份 Notebook 包含兩個主要部分：\n","1. **只使用 pandas + numpy + 標準函式庫，從零實作簡易 CNN**（教學示範，效能不佳但可理解原理）。\n","2. **使用 TensorFlow Keras 的標準 CNN 模型**，適合實際訓練與應用。\n","\n","你可以在 Colab 直接上傳 MNIST CSV 檔，或用 Keras 內建的 MNIST 資料集。"]},{"cell_type":"markdown","id":"8ef22cde","metadata":{"id":"8ef22cde"},"source":["## 0. 基本環境設定\n","\n","- 建議在 Google Colab 執行。\n","- 如果你使用 CSV 版本的 MNIST，請先把 `mnist_train.csv`、`mnist_test.csv` 上傳到 Colab。"]},{"cell_type":"code","execution_count":1,"id":"830d0d8c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":510,"status":"ok","timestamp":1765291934749,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"},"user_tz":-480},"id":"830d0d8c","outputId":"690fd3e7-0b7f-4906-a284-9b9cad65f309"},"outputs":[{"output_type":"stream","name":"stdout","text":["NumPy / Pandas 已載入完成\n"]}],"source":["# 如果在 Colab，可以先掛載 Google Drive（可選）：\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","import numpy as np\n","import pandas as pd\n","import math\n","\n","np.random.seed(42)\n","print(\"NumPy / Pandas 已載入完成\")"]},{"cell_type":"markdown","id":"cf08fe0b","metadata":{"id":"cf08fe0b"},"source":["## Part 1. 只用 pandas + numpy 的簡易 CNN\n","\n","這一部分示範：\n","- 從 CSV 載入 MNIST\n","- 自行實作：卷積層、ReLU、MaxPooling、全連接層、Softmax + Cross-Entropy\n","- 使用簡單 SGD 訓練\n","\n","> **提醒：** 這是教學示範，沒有任何最佳化，速度會比 Keras 版慢很多。"]},{"cell_type":"markdown","id":"e3ff8e3f","metadata":{"id":"e3ff8e3f"},"source":["### 1.1 載入與前處理 MNIST CSV\n","\n","假設：\n","- `mnist_train.csv`、`mnist_test.csv`\n","- 第一欄為 `label` (0–9)\n","- 其餘 784 欄為像素值（0–255）"]},{"cell_type":"code","execution_count":2,"id":"rp23S0nBNGfC","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22121,"status":"ok","timestamp":1765291960181,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"},"user_tz":-480},"id":"rp23S0nBNGfC","outputId":"8f6215b3-2b92-409a-dd16-f1419027bdfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"id":"ca444bba","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9875,"status":"ok","timestamp":1765291989367,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"},"user_tz":-480},"id":"ca444bba","outputId":"15e218ef-79c7-41fa-e991-2d4ee09f2e03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (60000, 785)\n","Test shape: (10000, 785)\n","X_train: (60000, 1, 28, 28) y_train: (60000,)\n"]}],"source":["# === 請確認檔名與路徑 ===\n","train_path = \"/content/drive/MyDrive/Colab Notebooks/Vibe Coding/Data/mnist_train.csv\"  # 例如：\"/content/mnist_train.csv\"\n","test_path  = \"/content/drive/MyDrive/Colab Notebooks/Vibe Coding/Data/mnist_test.csv\"   # 例如：\"/content/mnist_test.csv\"\n","\n","train_df = pd.read_csv(train_path)\n","test_df  = pd.read_csv(test_path)\n","\n","print(\"Train shape:\", train_df.shape)\n","print(\"Test shape:\", test_df.shape)\n","\n","# 取出 y 與 X\n","y_train = train_df.iloc[:, 0].values\n","X_train = train_df.iloc[:, 1:].values.astype(np.float32)\n","\n","y_test = test_df.iloc[:, 0].values\n","X_test = test_df.iloc[:, 1:].values.astype(np.float32)\n","\n","# 正規化到 0~1\n","X_train /= 255.0\n","X_test  /= 255.0\n","\n","# 轉成 (N, 1, 28, 28)\n","X_train = X_train.reshape(-1, 1, 28, 28)\n","X_test  = X_test.reshape(-1, 1, 28, 28)\n","\n","num_classes = 10\n","\n","def one_hot(y, num_classes=10):\n","    N = y.shape[0]\n","    oh = np.zeros((N, num_classes), dtype=np.float32)\n","    oh[np.arange(N), y] = 1.0\n","    return oh\n","\n","y_train_oh = one_hot(y_train, num_classes)\n","y_test_oh  = one_hot(y_test, num_classes)\n","\n","print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)"]},{"cell_type":"markdown","id":"c172d083","metadata":{"id":"c172d083"},"source":["### 1.2 自行實作 CNN 各層\n","\n","包含：\n","- `conv_forward` / `conv_backward`\n","- `relu_forward` / `relu_backward`\n","- `maxpool_forward` / `maxpool_backward`\n","- `linear_forward` / `linear_backward`\n","- `softmax_cross_entropy_loss`"]},{"cell_type":"code","execution_count":4,"id":"3f1ffcc5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1765291992514,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"},"user_tz":-480},"id":"3f1ffcc5","outputId":"b98cd5b4-ef4c-42b7-f6c4-71ad32027bfc"},"outputs":[{"output_type":"stream","name":"stdout","text":["CNN 各基本層函式定義完成（含完整中文註解）\n"]}],"source":["### 卷積層（Forward）\n","def conv_forward(input_tensor, weight, bias, padding=1, stride=1):\n","    \"\"\"\n","    input_tensor: (batch_size, in_channels, height, width)\n","    weight:       (out_channels, in_channels, kernel_size, kernel_size)\n","    bias:         (out_channels,)\n","    padding:      邊界補零數量\n","    stride:       每次卷積的步幅\n","    \"\"\"\n","\n","    # 取出輸入維度\n","    batch_size, in_channels, in_height, in_width = input_tensor.shape\n","    out_channels, _, kernel_size, _ = weight.shape\n","\n","    # 對輸入做 padding，使卷積可覆蓋邊緣像素\n","    input_padded = np.pad(\n","        input_tensor,\n","        ((0, 0), (0, 0), (padding, padding), (padding, padding)),\n","        mode=\"constant\"\n","    )\n","    _, _, padded_height, padded_width = input_padded.shape\n","\n","    # 計算輸出 feature map 的尺寸\n","    out_height = (padded_height - kernel_size) // stride + 1\n","    out_width = (padded_width - kernel_size) // stride + 1\n","\n","    # 初始化輸出\n","    out = np.zeros((batch_size, out_channels, out_height, out_width), dtype=np.float32)\n","\n","    # 卷積運算\n","    for n in range(batch_size):               # 每張圖片\n","        for out_c in range(out_channels):     # 每個濾波器\n","            for i in range(out_height):       # 垂直方向位置\n","                for j in range(out_width):    # 水平方向位置\n","                    h_start = i * stride\n","                    w_start = j * stride\n","                    # 卷積視窗取出區域，形狀 = (in_channels, kernel_size, kernel_size)\n","                    region = input_padded[n, :, h_start:h_start + kernel_size, w_start:w_start + kernel_size]\n","                    # 卷積公式： sum(region * weight) + bias\n","                    out[n, out_c, i, j] = np.sum(region * weight[out_c]) + bias[out_c]\n","\n","    # cache 用來存反向傳播需要的變數\n","    cache = (input_padded, weight, bias, padding, stride)\n","    return out, cache\n","\n","\n","### 卷積層（Backward）\n","def conv_backward(dout, cache):\n","    \"\"\"\n","    dout: 來自上層的梯度，shape = (batch_size, out_channels, out_height, out_width)\n","    \"\"\"\n","\n","    input_padded, weight, bias, padding, stride = cache\n","    batch_size, in_channels, padded_height, padded_width = input_padded.shape\n","    out_channels, _, kernel_size, _ = weight.shape\n","    _, _, out_height, out_width = dout.shape\n","\n","    # 初始化梯度\n","    d_input_padded = np.zeros_like(input_padded, dtype=np.float32)\n","    d_weight = np.zeros_like(weight, dtype=np.float32)\n","    d_bias = np.zeros_like(bias, dtype=np.float32)\n","\n","    # 計算梯度\n","    for n in range(batch_size):\n","        for out_c in range(out_channels):\n","            for i in range(out_height):\n","                for j in range(out_width):\n","                    h_start = i * stride\n","                    w_start = j * stride\n","                    region = input_padded[n, :, h_start:h_start + kernel_size, w_start:w_start + kernel_size]\n","\n","                    # bias 的梯度 = 對所有位置的 dout 相加\n","                    d_bias[out_c] += dout[n, out_c, i, j]\n","\n","                    # weight 的梯度 = 卷積視窗 * 上層梯度\n","                    d_weight[out_c] += dout[n, out_c, i, j] * region\n","\n","                    # input 梯度 = 上層梯度 * 濾波器權重\n","                    d_input_padded[n, :, h_start:h_start + kernel_size, w_start:w_start + kernel_size] += \\\n","                        dout[n, out_c, i, j] * weight[out_c]\n","\n","    # 去除 padding 部分，得到真正的 d_input\n","    if padding > 0:\n","        d_input = d_input_padded[:, :, padding:-padding, padding:-padding]\n","    else:\n","        d_input = d_input_padded\n","\n","    return d_input, d_weight, d_bias\n","\n","\n","### ReLU 層（Forward）\n","def relu_forward(input_tensor):\n","    \"\"\"\n","    ReLU(x) = max(0, x)\n","    \"\"\"\n","    out = np.maximum(0, input_tensor)  # 大於 0 保留，小於 0 設為 0\n","    cache = input_tensor               # 反向傳播需要知道正負訊息\n","    return out, cache\n","\n","\n","### ReLU 層（Backward）\n","def relu_backward(dout, cache):\n","    input_tensor = cache\n","    # ReLU 梯度：小於等於 0 的梯度為 0，大於 0 的梯度為 1\n","    d_input = dout * (input_tensor > 0)\n","    return d_input\n","\n","\n","### MaxPool 2x2（Forward）\n","def maxpool_forward(input_tensor, pool_size=2, stride=2):\n","    \"\"\"\n","    MaxPool: 在 pool_size x pool_size 區域內取最大值\n","    \"\"\"\n","    batch_size, channels, height, width = input_tensor.shape\n","    out_height = (height - pool_size) // stride + 1\n","    out_width = (width - pool_size) // stride + 1\n","\n","    out = np.zeros((batch_size, channels, out_height, out_width), dtype=np.float32)\n","    mask = np.zeros_like(input_tensor, dtype=np.float32)  # 紀錄最大值位置\n","\n","    for n in range(batch_size):\n","        for c in range(channels):\n","            for i in range(out_height):\n","                for j in range(out_width):\n","                    h_start = i * stride\n","                    w_start = j * stride\n","                    window = input_tensor[n, c, h_start:h_start + pool_size, w_start:w_start + pool_size]\n","\n","                    max_val = np.max(window)\n","                    out[n, c, i, j] = max_val\n","\n","                    # 找出最大值位置並作記號\n","                    max_pos = np.unravel_index(np.argmax(window), window.shape)\n","                    mask[n, c, h_start + max_pos[0], w_start + max_pos[1]] = 1.0\n","\n","    cache = (mask, pool_size, stride)\n","    return out, cache\n","\n","\n","### MaxPool 2x2（Backward）\n","def maxpool_backward(dout, cache):\n","    mask, pool_size, stride = cache\n","    batch_size, channels, height, width = mask.shape\n","    _, _, out_height, out_width = dout.shape\n","\n","    d_input = np.zeros_like(mask, dtype=np.float32)\n","\n","    for n in range(batch_size):\n","        for c in range(channels):\n","            for i in range(out_height):\n","                for j in range(out_width):\n","                    h_start = i * stride\n","                    w_start = j * stride\n","\n","                    # 只有當時紀錄的最大值位置會收到梯度\n","                    d_input[n, c, h_start:h_start + pool_size, w_start:w_start + pool_size] += \\\n","                        dout[n, c, i, j] * mask[n, c, h_start:h_start + pool_size, w_start:w_start + pool_size]\n","\n","    return d_input\n","\n","\n","### 全連接層（Forward）\n","def linear_forward(input_tensor, weight, bias):\n","    \"\"\"\n","    input_tensor: (batch_size, in_features)\n","    weight:       (in_features, out_features)\n","    bias:         (out_features,)\n","    \"\"\"\n","    out = input_tensor @ weight + bias\n","    cache = (input_tensor, weight, bias)\n","    return out, cache\n","\n","\n","### 全連接層（Backward）\n","def linear_backward(dout, cache):\n","    input_tensor, weight, bias = cache\n","\n","    d_input = dout @ weight.T          # 對輸入的梯度\n","    d_weight = input_tensor.T @ dout   # 對權重矩陣的梯度\n","    d_bias = np.sum(dout, axis=0)      # 對偏置的梯度（在 batch 上求和）\n","\n","    return d_input, d_weight, d_bias\n","\n","\n","### Softmax + Cross-Entropy（Forward + Backward 合併）\n","def softmax_cross_entropy_loss(logits, y_onehot):\n","    \"\"\"\n","    logits: (batch_size, num_classes)\n","    y_onehot: (batch_size, num_classes)\n","    \"\"\"\n","\n","    # Softmax（避免 overflow）\n","    logits_shifted = logits - np.max(logits, axis=1, keepdims=True)\n","    exp_scores = np.exp(logits_shifted)\n","    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n","\n","    # Cross Entropy Loss\n","    batch_size = logits.shape[0]\n","    loss = -np.sum(y_onehot * np.log(probs + 1e-9)) / batch_size\n","\n","    # Softmax + Cross Entropy 梯度簡化公式： (p - y) / N\n","    d_logits = (probs - y_onehot) / batch_size\n","\n","    return loss, d_logits, probs\n","\n","\n","print(\"CNN 各基本層函式定義完成（含完整中文註解）\")\n"]},{"cell_type":"markdown","id":"b928c182","metadata":{"id":"b928c182"},"source":["### 1.3 建立簡易 CNN 模型（1 層 Conv + MaxPool + FC）\n","\n","架構：\n","- Conv2D：輸入 (1, 28, 28) → 8 個 3×3 filter (padding=1)\n","- ReLU\n","- MaxPool2D：2×2, stride=2 → 特徵圖大小 14×14\n","- Flatten\n","- 全連接層：8×14×14 → 10 類別\n","- Softmax + Cross-Entropy"]},{"cell_type":"code","execution_count":10,"id":"f0890237","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1765292131689,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"},"user_tz":-480},"id":"f0890237","outputId":"cb47dfc2-0bb0-48b5-efa3-9d1fddbf6716"},"outputs":[{"output_type":"stream","name":"stdout","text":["簡易 CNN 模型初始化完成\n"]}],"source":["import numpy as np\n","# 定義模型結構與前向/反向\n","C_in = 1\n","C_out = 8\n","K = 3\n","pad = 1\n","stride = 1\n","\n","H_out_conv = 28  # padding=1, stride=1 -> 高度不變\n","W_out_conv = 28\n","H_pool = H_out_conv // 2\n","W_pool = W_out_conv // 2\n","D_flat = C_out * H_pool * W_pool  # 8 * 14 * 14 = 1568\n","\n","rng = np.random.default_rng(42)\n","W1 = rng.normal(0, 0.1, size=(C_out, C_in, K, K)).astype(np.float32)\n","b1 = np.zeros(C_out, dtype=np.float32)\n","W2 = rng.normal(0, 0.1, size=(D_flat, num_classes)).astype(np.float32)\n","b2 = np.zeros(num_classes, dtype=np.float32)\n","\n","def forward_pass(X):\n","    # Conv\n","    z1, cache_conv = conv_forward(X, W1, b1, padding=pad, stride=stride)\n","    # ReLU\n","    a1, cache_relu = relu_forward(z1)\n","    # MaxPool\n","    p1, cache_pool = maxpool_forward(a1, pool_size=2, stride=2)\n","    # Flatten\n","    N = X.shape[0]\n","    flat = p1.reshape(N, -1)\n","    cache_flat = p1.shape\n","    # Linear\n","    logits, cache_fc = linear_forward(flat, W2, b2)\n","\n","    caches = (cache_conv, cache_relu, cache_pool, cache_flat, cache_fc)\n","    return logits, caches\n","\n","def backward_pass(dlogits, caches):\n","    global W1, b1, W2, b2\n","    cache_conv, cache_relu, cache_pool, cache_flat, cache_fc = caches\n","\n","    dflat, dW2, db2_ = linear_backward(dlogits, cache_fc)\n","    dpool = dflat.reshape(cache_flat)\n","    da1 = maxpool_backward(dpool, cache_pool)\n","    dz1 = relu_backward(da1, cache_relu)\n","    dX, dW1, db1_ = conv_backward(dz1, cache_conv)\n","\n","    return dW1, db1_, dW2, db2_\n","\n","def accuracy(X, y_true, batch_size=256):\n","    N = X.shape[0]\n","    correct = 0\n","    total = 0\n","    for i in range(0, N, batch_size):\n","        X_batch = X[i:i+batch_size]\n","        y_batch = y_true[i:i+batch_size]\n","        logits, _ = forward_pass(X_batch)\n","        preds = np.argmax(logits, axis=1)\n","        correct += np.sum(preds == y_batch)\n","        total += y_batch.shape[0]\n","    return correct / total\n","\n","print(\"簡易 CNN 模型初始化完成\")\n"]},{"cell_type":"markdown","id":"0f10ba86","metadata":{"id":"0f10ba86"},"source":["### 1.4 訓練迴圈（示範）\n","\n","- 為了節省時間，先只用部分訓練資料（例如前 10000 筆）。\n","- 可以自行把 `N_train_use` 改為全部樣本數。"]},{"cell_type":"code","execution_count":11,"id":"cfee344c","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"cfee344c","executionInfo":{"status":"error","timestamp":1765293233259,"user_tz":-480,"elapsed":1098465,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"}},"outputId":"7f9d3b0a-8dbc-4370-8af9-712567f6777a"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1000345789.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my_batch_oh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_tr_oh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_cross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1240216987.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m# ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_relu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3380981506.py\u001b[0m in \u001b[0;36mconv_forward\u001b[0;34m(input_tensor, weight, bias, padding, stride)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mregion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mw_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0;31m# 卷積公式： sum(region * weight) + bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# cache 用來存反向傳播需要的變數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m     return _wrapreduction(\n\u001b[0m\u001b[1;32m   2390\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m         \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[1;32m     71\u001b[0m                   if v is not np._NoValue}\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 訓練設定\n","N_train_use = 10000  # 可以改成 len(X_train) 使用全部資料\n","X_tr = X_train[:N_train_use]\n","y_tr = y_train[:N_train_use]\n","y_tr_oh = y_train_oh[:N_train_use]\n","\n","learning_rate = 0.01\n","num_epochs = 3\n","batch_size = 64\n","\n","for epoch in range(num_epochs):\n","    idx = np.random.permutation(N_train_use)\n","    X_tr = X_tr[idx]\n","    y_tr = y_tr[idx]\n","    y_tr_oh = y_tr_oh[idx]\n","\n","    total_loss = 0.0\n","    num_batches = 0\n","\n","    for i in range(0, N_train_use, batch_size):\n","        X_batch = X_tr[i:i+batch_size]\n","        y_batch_oh = y_tr_oh[i:i+batch_size]\n","\n","        logits, caches = forward_pass(X_batch)\n","        loss, dlogits, probs = softmax_cross_entropy_loss(logits, y_batch_oh)\n","        total_loss += loss\n","        num_batches += 1\n","\n","        dW1, db1_, dW2, db2_ = backward_pass(dlogits, caches)\n","\n","        W1 -= learning_rate * dW1\n","        b1 -= learning_rate * db1_\n","        W2 -= learning_rate * dW2\n","        b2 -= learning_rate * db2_\n","\n","    train_acc = accuracy(X_tr, y_tr)\n","    test_acc = accuracy(X_test, y_test)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs} \"\n","          f\"Loss = {total_loss/num_batches:.4f}, \"\n","          f\"Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")"]},{"cell_type":"markdown","id":"b8d96832","metadata":{"id":"b8d96832"},"source":["---\n","## Part 2. 使用 TensorFlow Keras 的 CNN\n","\n","這一部分改用 TensorFlow Keras：\n","- 直接載入 Keras 內建 MNIST\n","- 建立標準 CNN 模型\n","- 編譯與訓練\n","- 評估與簡單預測\n"]},{"cell_type":"markdown","id":"b29a07f8","metadata":{"id":"b29a07f8"},"source":["### 2.1 載入與前處理 MNIST（Keras 內建）"]},{"cell_type":"code","execution_count":null,"id":"082ec154","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15169,"status":"ok","timestamp":1765268922509,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"},"user_tz":-480},"id":"082ec154","outputId":"6acf9d0e-0bc3-4e93-d01f-b72296787344"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 版本： 2.19.0\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","x_train shape: (60000, 28, 28, 1)\n","y_train shape: (60000,)\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","print(\"TensorFlow 版本：\", tf.__version__)\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255.0\n","x_test  = x_test.astype('float32') / 255.0\n","\n","# 增加通道維度 (N, 28, 28, 1)\n","x_train = x_train[..., tf.newaxis]\n","x_test  = x_test[..., tf.newaxis]\n","\n","num_classes = 10\n","print(\"x_train shape:\", x_train.shape)\n","print(\"y_train shape:\", y_train.shape)"]},{"cell_type":"markdown","id":"cc8b10a4","metadata":{"id":"cc8b10a4"},"source":["### 2.2 建立 CNN 模型"]},{"cell_type":"code","execution_count":null,"id":"abd39cca","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1765268924116,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"},"user_tz":-480},"id":"abd39cca","outputId":"14ec87ab-5097-4033-c84d-38e494436bde"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m102,464\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,930</span> (476.29 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,930\u001b[0m (476.29 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,930</span> (476.29 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121,930\u001b[0m (476.29 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax'),\n","])\n","\n","model.summary()"]},{"cell_type":"markdown","id":"251967ef","metadata":{"id":"251967ef"},"source":["### 2.3 編譯與訓練"]},{"cell_type":"code","execution_count":null,"id":"43e5372a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292500,"status":"ok","timestamp":1765269218674,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"},"user_tz":-480},"id":"43e5372a","outputId":"d272b2c0-196f-4d44-86cc-f2f90f924aa7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 100ms/step - accuracy: 0.8089 - loss: 0.6057 - val_accuracy: 0.9785 - val_loss: 0.0725\n","Epoch 2/5\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 96ms/step - accuracy: 0.9782 - loss: 0.0681 - val_accuracy: 0.9848 - val_loss: 0.0538\n","Epoch 3/5\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 95ms/step - accuracy: 0.9856 - loss: 0.0457 - val_accuracy: 0.9872 - val_loss: 0.0440\n","Epoch 4/5\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 98ms/step - accuracy: 0.9891 - loss: 0.0356 - val_accuracy: 0.9847 - val_loss: 0.0495\n","Epoch 5/5\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 94ms/step - accuracy: 0.9920 - loss: 0.0270 - val_accuracy: 0.9902 - val_loss: 0.0358\n","Test accuracy: 0.9893\n"]}],"source":["model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy'],\n",")\n","\n","history = model.fit(\n","    x_train, y_train,\n","    epochs=5,\n","    batch_size=128,\n","    validation_split=0.1,\n","    verbose=1\n",")\n","\n","test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n","print(f\"Test accuracy: {test_acc:.4f}\")"]},{"cell_type":"markdown","id":"55ba45e2","metadata":{"id":"55ba45e2"},"source":["### 2.4 預測與範例輸出"]},{"cell_type":"code","execution_count":null,"id":"6fe24c38","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93,"status":"ok","timestamp":1765269341125,"user":{"displayName":"Cho-Hsun Lu","userId":"08025011276150415219"},"user_tz":-480},"id":"6fe24c38","outputId":"1a1b6466-5737-422d-ba07-c6e3b222a529"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","真實標籤： [6 5 4 2 9]\n","預測結果： [6 5 4 2 9]\n"]}],"source":["import numpy as np\n","\n","idx = np.random.choice(len(x_test), size=5, replace=False)\n","x_sample = x_test[idx]\n","y_true = y_test[idx]\n","\n","y_pred_prob = model.predict(x_sample)\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","print(\"真實標籤：\", y_true)\n","print(\"預測結果：\", y_pred)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}